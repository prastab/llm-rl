{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## First, check to see if lightning is installed, if not, install it.\nimport pip\ntry:\n  __import__(\"lightning\")\nexcept ImportError:\n  pip.main(['install', \"lightning\"])  \n\nimport torch ## torch let's us create tensors and also provides helper functions\nimport torch.nn as nn ## torch.nn gives us nn.Module(), nn.Embedding() and nn.Linear()\nimport torch.nn.functional as F # This gives us the softmax() and argmax()\nfrom torch.optim import Adam ## We will use the Adam optimizer, which is, essentially, \n                             ## a slightly less stochastic version of stochastic gradient descent.\nfrom torch.utils.data import TensorDataset, DataLoader ## We'll store our data in DataLoaders\n\nimport lightning as L ## Lightning makes it easier to write, optimize and scale our code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:45:13.157893Z","iopub.execute_input":"2025-03-20T18:45:13.158197Z","iopub.status.idle":"2025-03-20T18:45:17.024539Z","shell.execute_reply.started":"2025-03-20T18:45:13.158158Z","shell.execute_reply":"2025-03-20T18:45:17.023689Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from typing import List\nimport random\nfrom torch.nn.utils.rnn import pad_sequence\n\nfrom typing import List\nimport random\n\ndef generate_synthetic_data(num_data: int, max_digits: int) -> List[List[int]]:\n    \"\"\"\n    Generate synthetic data for training the language model.\n\n    Args: \n        num_data (int): Number of data points to generate.\n        max_digits (int): Maximum number of digits (not directly used; kept for compatibility).\n\n    Returns:\n        List[List[int]]: List of sequences, where each sequence is a list of token IDs.\n    \"\"\"\n    # Define the token-to-ID mapping\n    token_to_id = {\n        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4,\n        '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n        '.': 10,\n        'or': 11,\n        '<': 12,\n        '>': 13,\n        '=': 14,\n        '[BOS]': 15,\n        '[EOS]': 16,\n        '[SEP]': 17,\n        '[PAD]': 18\n    }\n\n    def generate_number():\n        # Integer part: 0 to 9999 ensures up to 4 digits\n        int_part = str(random.randint(0, 999))\n        # Decide whether to include a decimal part (50% chance)\n        if random.random() < 0.7:\n            # Decimal digits: 1 or 2\n            dec_digits = random.randint(1, 2)\n            dec_part = ''.join(str(random.randint(0, 9)) for _ in range(dec_digits))\n            return int_part + '.' + dec_part\n        return int_part\n\n    sequences = []\n    for _ in range(num_data):\n        # Generate two numbers\n        num1_str = generate_number()\n        num2_str = generate_number()\n        \n        # Convert to floats for comparison\n        num1_float = float(num1_str)\n        num2_float = float(num2_str)\n        \n        # Determine the operator\n        if num1_float < num2_float:\n            operator = '<'\n        elif num1_float > num2_float:\n            operator = '>'\n        else:\n            operator = '='\n        \n        # Construct the sequence\n        input_part = f\"[BOS]{num1_str}or{num2_str}[SEP]\"\n        output_part = f\"{num1_str}{operator}{num2_str}[EOS]\"\n        sequence_str = input_part + output_part\n        \n        # Tokenize the sequence\n        sequence_tokens = []\n        i = 0\n        while i < len(sequence_str):\n            if sequence_str[i:i+5] in ('[BOS]', '[EOS]', '[SEP]'):\n                sequence_tokens.append(sequence_str[i:i+5])\n                i += 5\n            elif sequence_str[i:i+2] == 'or':\n                sequence_tokens.append('or')\n                i += 2\n            else:\n                sequence_tokens.append(sequence_str[i])\n                i += 1\n        \n        # Map tokens to IDs\n        sequence_ids = [token_to_id[token] for token in sequence_tokens]\n        sequences.append(sequence_ids)\n\n    return sequences\ntoken_to_id = {\n        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4,\n        '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n        '.': 10,\n        'or': 11,\n        '<': 12,\n        '>': 13,\n        '=': 14,\n        '[BOS]': 15,\n        '[EOS]': 16,\n        '[SEP]': 17,\n        '[PAD]': 18\n    }\n\nid_to_token = dict(map(reversed, token_to_id.items()))\n\ndata = generate_synthetic_data(num_data=100000, max_digits=2)\n\nprint(data[0])\nprint(\"Generated sequence (text):\", \"\".join([id_to_token[token_id] for token_id in data[0]]))\n\n# Convert to tensors\ndata_tensors = [torch.tensor(seq, dtype=torch.long) for seq in data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:45:20.728080Z","iopub.execute_input":"2025-03-20T18:45:20.728586Z","iopub.status.idle":"2025-03-20T18:45:23.412844Z","shell.execute_reply.started":"2025-03-20T18:45:20.728543Z","shell.execute_reply":"2025-03-20T18:45:23.412130Z"}},"outputs":[{"name":"stdout","text":"[15, 3, 2, 5, 10, 6, 6, 11, 9, 4, 8, 10, 7, 17, 3, 2, 5, 10, 6, 6, 12, 9, 4, 8, 10, 7, 16]\nGenerated sequence (text): [BOS]325.66or948.7[SEP]325.66<948.7[EOS]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_size = int(0.9 * len(data_tensors))  # 90% for training\nval_size = len(data_tensors) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(data_tensors, [train_size, val_size])\n\ndef collate_fn(batch):\n    return pad_sequence(batch, batch_first=True, padding_value=0)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)\nval_dataloader = DataLoader(val_dataset, batch_size=1024, shuffle=False, collate_fn=collate_fn, num_workers=4, pin_memory=True)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:45:25.109078Z","iopub.execute_input":"2025-03-20T18:45:25.109410Z","iopub.status.idle":"2025-03-20T18:45:25.122702Z","shell.execute_reply.started":"2025-03-20T18:45:25.109381Z","shell.execute_reply":"2025-03-20T18:45:25.121900Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class PositionEncoding(nn.Module):\n    def __init__(self, d_model: int, max_len: int = 50):\n        super().__init__()\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n        pe = torch.zeros(1, max_len, d_model)  # Shape: (1, max_len, d_model) for batch-first\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x: (batch_size, seq_len, d_model)\n        x = x + self.pe[:, :x.size(1), :]  # Slice to seq_len, broadcast over batch\n        return x\n\nclass Attention(nn.Module):\n    def __init__(self, d_model: int):\n        super().__init__()\n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.d_model = d_model\n\n    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n        q = self.W_q(encodings_for_q)\n        k = self.W_k(encodings_for_k)\n        v = self.W_v(encodings_for_v)\n        \n        # Scaled dot-product attention\n        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n\n        if mask is not None:\n            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n\n        attn_probs = torch.softmax(attn_scores, dim=-1)\n        output = torch.matmul(attn_probs, v)\n        return output\n\n\nclass DecoderLayer(nn.Module):\n  def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n      super().__init__()\n      self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n      self.norm1 = nn.LayerNorm(d_model)\n      self.ff = nn.Sequential(\n            nn.Linear(d_model, d_ff),\n            nn.ReLU(),\n            nn.Linear(d_ff, d_model)\n          )\n      self.norm2 = nn.LayerNorm(d_model)\n      self.dropout = nn.Dropout(dropout)\n\n\n  def forward(self, x, mask):\n    # Self-attention with residual connection and layer normalization\n    attn_output, _ = self.self_attn(x, x, x, attn_mask=mask)\n    x = self.norm1(x + self.dropout(attn_output))\n\n    # Feedforward network with residual and layer normalization.\n    ff_output = self.ff(x)\n    x = self.norm2(x + self.dropout(ff_output))\n\n    return x\n    \n\nclass DecoderOnlyTransformer(L.LightningModule):\n    def __init__(self, num_tokens: int = 19, d_model: int = 128, num_heads: int = 4, num_layers: int = 3, d_ff: int = 512, max_len: int = 100, dropout=0.1):\n        super().__init__()\n        L.seed_everything(seed=42)\n        self.embedding = nn.Embedding(num_tokens, d_model)\n        self.pos_encoding = PositionEncoding(d_model, max_len)\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.fc_out = nn.Linear(d_model, num_tokens)\n        self.dropout = nn.Dropout(dropout)\n        self.loss = nn.CrossEntropyLoss(ignore_index=18)\n        self.d_model = d_model\n\n    def forward(self, x, mask):\n      x = self.embedding(x) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32)) # Scale embeddings\n      x = self.pos_encoding(x)\n      x = self.dropout(x)\n      for layer in self.decoder_layers:\n          x = layer(x, mask)\n      x = self.fc_out(x)\n      return x\n\n\n    def configure_optimizers(self):\n        return Adam(self.parameters(), lr=3e-4)\n\n    def training_step(self, batch, batch_idx):\n        inputs = batch[:, :-1]\n        labels = batch[:, 1:]\n        mask = self.generate_square_subsequent_mask(inputs.size(1)).to(inputs.device)\n        output = self.forward(inputs, mask)\n        output = output.view(-1, output.size(-1))\n        labels = labels.contiguous().view(-1)\n        loss = self.loss(output, labels)\n        self.log('train_loss', loss)\n        # print(\"Batch:\", batch_idx)\n        # print(\"Loss: \", loss.item())\n        return loss\n    def validation_step(self, batch, batch_idx):\n        inputs = batch[:, :-1]\n        labels = batch[:, 1:]\n        mask = self.generate_square_subsequent_mask(inputs.size(1)).to(inputs.device)\n        output = self.forward(inputs, mask)\n        output = output.view(-1, output.size(-1))\n        labels_flat = labels.contiguous().view(-1)\n        loss = self.loss(output, labels_flat)\n        predictions = torch.argmax(output, dim=-1)\n        correct_predictions = (predictions == labels_flat)\n        non_padding_mask = (labels_flat != 0)\n        accuracy = (correct_predictions & non_padding_mask).float().sum() / non_padding_mask.float().sum()\n        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val_acc', accuracy, on_step=False, on_epoch=True, prog_bar=True)\n        # print(\"Validation Loss: \", loss.item())\n        # print(\"Validation Accuracy:\", accuracy.item())\n        return loss\n\n    def generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n        \"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n        Unmasked positions are filled with float(0.0).\n        \"\"\"\n        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n\n    def generate(self, input_sequence, max_length=20):\n      self.eval()  # Set the model to evaluation mode\n      with torch.no_grad():  # Disable gradient calculation\n          input_tensor = torch.tensor(input_sequence, dtype=torch.long).unsqueeze(0).to(self.device) # Add batch dimension and move to device\n          output = input_tensor\n          for _ in range(max_length):\n                mask = self.generate_square_subsequent_mask(output.size(1)).to(self.device)\n                predictions = self.forward(output, mask)\n                # Get the last predicted token\n                next_token_prediction = predictions[:, -1, :]\n                # Get the most likely next token\n                next_token = torch.argmax(next_token_prediction, dim=-1)\n                # Concatenate the next token to the output sequence\n                output = torch.cat([output, next_token.unsqueeze(0)], dim=1)\n\n                # If the next token is [EOS], stop generating\n                if next_token.item() == 16: # [EOS] token ID\n                    break\n      return output.squeeze(0).tolist() # remove the batch dimension","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:45:26.905843Z","iopub.execute_input":"2025-03-20T18:45:26.906143Z","iopub.status.idle":"2025-03-20T18:45:26.926643Z","shell.execute_reply.started":"2025-03-20T18:45:26.906119Z","shell.execute_reply":"2025-03-20T18:45:26.925637Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\nnum_tokens = 19\nd_model = 32\nnum_heads = 4\nnum_layers = 8\nd_ff = 1024\nmax_len = 50\ndropout = 0.1\n\n# --- Model Creation ---\nmodel = DecoderOnlyTransformer(num_tokens, d_model, num_heads, num_layers, d_ff, max_len, dropout)\n\n# --- Training (using Lightning) ---\ntrainer = L.Trainer(\n    max_epochs=10,  # More epochs\n    accelerator=\"gpu\",\n    devices=\"auto\",\n    gradient_clip_val=0.5, \n    # accumulate_grad_batches = 2 # Add gradient clipping\n    # profiler=\"simple\", # uncomment for profiling\n)\ntrainer.fit(model, train_dataloader, val_dataloader)  \ntrainer.save_checkpoint(\"/kaggle/working/base.ckpt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint_path = \"/kaggle/working/start2.ckpt\" \n\n# num_tokens = 19\n# d_model = 64\n# num_heads = 8\n# num_layers = 8\n# d_ff = 2048\n# max_len = 50\n# dropout = 0.1\n\n# model = DecoderOnlyTransformer.load_from_checkpoint(\n#     checkpoint_path,\n#     num_tokens=num_tokens,  # Pass hyperparameters to reconstruct the model\n#     d_model=d_model,\n#     num_heads=num_heads,\n#     num_layers=num_layers,\n#     d_ff=d_ff,\n#     max_len=max_len,\n#     dropout=dropout\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## New RL Method with log(p) and log(1-p)","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nclass ImprovedRLFineTuner:\n    def __init__(self, model, learning_rate=1e-5, gamma=0.99):\n        \"\"\"Initialize the improved RL fine-tuner.\"\"\"\n        self.model = model\n        self.model.train()\n        \n        # Use a smaller learning rate for stability\n        self.optimizer = Adam(self.model.parameters(), lr=learning_rate)\n        self.gamma = gamma\n        \n        # Create token mappings for easier reference\n        self.id_to_token = {\n            0: '0', 1: '1', 2: '2', 3: '3', 4: '4',\n            5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n            10: '.', 11: 'or', 12: '<', 13: '>', \n            14: '=', 15: '[BOS]', 16: '[EOS]', 17: '[SEP]', 18: '[PAD]'\n        }\n        \n        # Track metrics\n        self.rewards_history = []\n        self.accuracy_history = []\n    \n    def parse_numbers(self, sequence):\n        \"\"\"Extract the two numbers from a sequence for comparison.\"\"\"\n        # Convert sequence to string\n        if isinstance(sequence, list) or isinstance(sequence, torch.Tensor):\n            sequence = \"\".join([self.id_to_token.get(int(token), \"\") for token in sequence])\n        \n        # Find the position of 'or'\n        or_pos = sequence.find('or')\n        if or_pos == -1:\n            return None, None\n        \n        # Find the position of [BOS] and [SEP]\n        bos_pos = sequence.find('[BOS]')\n        sep_pos = sequence.find('[SEP]')\n        \n        if bos_pos == -1 or sep_pos == -1:\n            return None, None\n        \n        # Extract the numbers\n        num1_str = sequence[bos_pos+5:or_pos]\n        num2_str = sequence[or_pos+2:sep_pos]\n        \n        try:\n            num1 = float(num1_str)\n            num2 = float(num2_str)\n            return num1, num2\n        except ValueError:\n            return None, None\n    \n    def compute_reward(self, generated_sequence, input_sequence):\n        \"\"\"Compute reward based on correct comparison operator.\"\"\"\n        # Parse numbers from input\n        num1, num2 = self.parse_numbers(input_sequence)\n        if num1 is None or num2 is None:\n            return -1  # Invalid input\n        \n        # Determine correct operator\n        correct_op = '<' if num1 < num2 else '>' if num1 > num2 else '='\n        correct_op_id = 12 if correct_op == '<' else 13 if correct_op == '>' else 14\n        \n        # Find operator in generated sequence\n        generated_op = None\n        for token in generated_sequence:\n            if token in [12, 13, 14]:  # < or > or =\n                generated_op = token\n                break\n        \n        # No operator found - large penalty\n        if generated_op is None:\n            return -1\n        \n        # Compare with correct operator\n        if generated_op == correct_op_id:\n            return 1.0  # Correct comparison\n        else:\n            return -1.0  # Incorrect comparison\n    \n    def train_one_epoch(self, dataloader):\n        \"\"\"Train for one epoch using both correct and incorrect examples with different weights.\"\"\"\n        total_reward = 0\n        total_correct = 0\n        total_samples = 0\n        \n        self.model.train()\n        \n        # Process batches\n        for batch in tqdm(dataloader, desc=\"Training\"):\n            batch = batch.to(self.model.device)\n            batch_size = batch.size(0)\n            \n            for i in range(batch_size):\n                # Find the separator token ([SEP]) position\n                sep_positions = (batch[i] == 17).nonzero(as_tuple=True)[0]\n                if len(sep_positions) == 0:\n                    continue  # Skip if no separator\n                    \n                sep_position = sep_positions[0].item()\n                \n                # Input is everything up to and including [SEP]\n                input_seq = batch[i, :sep_position+1].unsqueeze(0)\n                \n                # 1. Generate the sequence with the current model\n                with torch.no_grad():\n                    generated = self.model.generate(input_seq[0].tolist())\n                \n                # 2. Compute reward\n                reward = self.compute_reward(generated, batch[i].tolist())\n                total_reward += reward\n                \n                # Check if prediction is correct\n                is_correct = reward > 0\n                if is_correct:\n                    total_correct += 1\n                total_samples += 1\n                \n                # 3. Create a modified target sequence with the correct operator\n                num1, num2 = self.parse_numbers(batch[i].tolist())\n                \n                if num1 is not None and num2 is not None:\n                    # Determine correct operator\n                    correct_op_id = 12 if num1 < num2 else 13 if num1 > num2 else 14\n                    \n                    # Extract parts before and after the operator from the target\n                    target_parts = []\n                    op_found = False\n                    \n                    for token in batch[i].tolist():\n                        if token in [12, 13, 14]:  # Found an operator\n                            target_parts.append(correct_op_id)  # Replace with correct operator\n                            op_found = True\n                        else:\n                            target_parts.append(token)\n                    \n                    if not op_found:\n                        continue  # Skip if no operator in target\n                    \n                    # Create target tensor\n                    target = torch.tensor(target_parts, device=self.model.device).unsqueeze(0)\n                    \n                    # 4. Compute loss with this target and update\n                    # Create inputs for the model (everything except the last token)\n                    inputs = target[:, :-1]\n                    # Create targets (everything except the first token - shifted by 1)\n                    targets = target[:, 1:]\n                    \n                    # Create appropriate mask\n                    mask = self.model.generate_square_subsequent_mask(inputs.size(1)).to(self.model.device)\n                    \n                    # Forward pass\n                    output = self.model(inputs, mask)\n                    \n                    # Custom loss computation\n                    epsilon = 1e-8  # Small value to prevent log(0)\n                    p = torch.softmax(output, dim=-1)  # [1, seq_len_inputs, vocab_size], probabilities\n                    \n                    # Get probabilities of correct tokens (targets)\n                    p_ct = p.gather(dim=-1, index=targets.unsqueeze(-1)).squeeze(-1)  # [1, seq_len_inputs]\n                    \n                    # Compute -log(p) for correct tokens\n                    neg_log_p_ct = -torch.log(p_ct + epsilon)  # [1, seq_len_inputs]\n                    \n                    # Get the model's actual predictions (highest probability tokens)\n                    predicted_tokens = torch.argmax(p, dim=-1)  # [1, seq_len_inputs]\n                    \n                    # Create a mask where predictions don't match targets\n                    incorrect_mask = (predicted_tokens != targets)  # [1, seq_len_inputs]\n                    \n                    # Get probabilities of predicted tokens\n                    p_pred = p.gather(dim=-1, index=predicted_tokens.unsqueeze(-1)).squeeze(-1)  # [1, seq_len_inputs]\n                    \n                    # Compute -log(1 - p) for incorrect predictions only\n                    neg_log_one_minus_p_incorrect = torch.zeros_like(p_ct)  # [1, seq_len_inputs]\n                    neg_log_one_minus_p_incorrect[incorrect_mask] = -torch.log(1 - p_pred[incorrect_mask] + epsilon)\n                    \n                    # Total loss per position: -log(p) for correct + -log(1-p) for incorrect predictions\n                    loss_per_position = neg_log_p_ct + neg_log_one_minus_p_incorrect  # [1, seq_len_inputs]\n                    \n                    # Exclude padding tokens (ID 18) from loss\n                    valid_mask = (targets != 18)  # [1, seq_len_inputs]\n                    if valid_mask.sum() == 0:\n                        continue  # Skip if all tokens are padding\n                    \n                    # Average loss over valid positions\n                    loss = loss_per_position[valid_mask].mean()\n                    \n                    # Apply different scaling based on whether prediction was correct\n                    if is_correct:\n                        # For correct predictions, use a smaller weight\n                        loss = loss * 0.2  # 5x smaller weight than incorrect predictions\n                    else:\n                        # For incorrect predictions, use a larger weight\n                        loss = loss * abs(reward)  # Full weight based on reward magnitude\n                    \n                    # Update\n                    self.optimizer.zero_grad()\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n                    self.optimizer.step()\n        \n        # Calculate statistics\n        avg_reward = total_reward / max(total_samples, 1)\n        accuracy = total_correct / max(total_samples, 1)\n        \n        self.rewards_history.append(avg_reward)\n        self.accuracy_history.append(accuracy)\n        \n        print(f\"Epoch stats - Avg Reward: {avg_reward:.4f}, Accuracy: {accuracy:.4f}\")\n        return avg_reward, accuracy\n    \n    def evaluate(self, dataloader):\n        \"\"\"Evaluate the model on a validation set.\"\"\"\n        self.model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for batch in tqdm(dataloader, desc=\"Evaluating\"):\n                batch = batch.to(self.model.device)\n                \n                for i in range(batch.size(0)):\n                    # Find separator position\n                    sep_positions = (batch[i] == 17).nonzero(as_tuple=True)[0]\n                    if len(sep_positions) == 0:\n                        continue\n                        \n                    sep_position = sep_positions[0].item()\n                    \n                    # Extract input sequence\n                    input_seq = batch[i, :sep_position+1].tolist()\n                    \n                    # Extract numbers for comparison\n                    num1, num2 = self.parse_numbers(batch[i].tolist())\n                    if num1 is None or num2 is None:\n                        continue\n                        \n                    # Determine correct operator\n                    correct_op_id = 12 if num1 < num2 else 13 if num1 > num2 else 14\n                    \n                    # Generate prediction\n                    try:\n                        generated = self.model.generate(input_seq)\n                        \n                        # Find generated operator\n                        gen_op = None\n                        for token in generated:\n                            if token in [12, 13, 14]:  # < or > or =\n                                gen_op = token\n                                break\n                                \n                        if gen_op is not None:\n                            total += 1\n                            if gen_op == correct_op_id:\n                                correct += 1\n                                \n                    except Exception as e:\n                        print(f\"Error during evaluation: {e}\")\n        \n        accuracy = correct / max(total, 1)\n        print(f\"Evaluation Results: {correct}/{total} correct = {accuracy:.4f} accuracy\")\n        return accuracy\n    \n    def fine_tune(self, train_dataloader, val_dataloader, num_epochs=3):\n        \"\"\"Fine-tune the model for multiple epochs.\"\"\"\n        # First evaluate the model\n        print(\"Initial evaluation:\")\n        initial_accuracy = self.evaluate(val_dataloader)\n        \n        best_accuracy = initial_accuracy\n        best_model_state = self.model.state_dict().copy()\n        \n        for epoch in range(num_epochs):\n            print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n            \n            # Train for one epoch\n            reward, train_acc = self.train_one_epoch(train_dataloader)\n            \n            # Evaluate\n            val_accuracy = self.evaluate(val_dataloader)\n            \n            # Save best model\n            if val_accuracy > best_accuracy:\n                best_accuracy = val_accuracy\n                best_model_state = self.model.state_dict().copy()\n                print(f\"New best model with accuracy: {best_accuracy:.4f}\")\n        \n        # Restore best model\n        self.model.load_state_dict(best_model_state)\n        print(f\"Fine-tuning complete. Best accuracy: {best_accuracy:.4f}\")\n        return best_accuracy\n    \n    def save_model(self, path):\n        \"\"\"Save the fine-tuned model.\"\"\"\n        torch.save(self.model.state_dict(), path)\n\n# Run improved fine-tuning\ndef run_improved_finetuning():\n    # Start with a fresh copy of the original pre-trained model\n    model = DecoderOnlyTransformer.load_from_checkpoint(\n        \"/kaggle/working/base.ckpt\",\n       num_tokens=19, \n        d_model=32, \n        num_heads=4, \n        num_layers=8, \n        d_ff=1024, \n        max_len=50, \n        dropout=0.1\n    )\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    # Create datasets with a variety of comparison examples\n    print(\"Generating training data...\")\n    train_data = generate_synthetic_data(num_data=5000, max_digits=3)\n    train_tensors = [torch.tensor(seq, dtype=torch.long) for seq in train_data]\n    train_dataloader = DataLoader(train_tensors, batch_size=64, shuffle=True, collate_fn=collate_fn)\n    \n    print(\"Generating validation data...\")\n    val_data = generate_synthetic_data(num_data=500, max_digits=3)\n    val_tensors = [torch.tensor(seq, dtype=torch.long) for seq in val_data]\n    val_dataloader = DataLoader(val_tensors, batch_size=64, shuffle=False, collate_fn=collate_fn)\n    \n    # Create fine-tuner\n    finetuner = ImprovedRLFineTuner(model, learning_rate=5e-6)\n    \n    # Fine-tune\n    finetuner.fine_tune(train_dataloader, val_dataloader, num_epochs=3)\n    \n    # Save model\n    finetuner.save_model(\"/kaggle/working/true_rl.pt\")\n    \n    # Test examples\n    test_examples = [\n        # [BOS]212.91or211.19[SEP]\n        [15, 2, 1, 2, 10, 9, 1, 11, 2, 1, 1, 10, 1, 9, 17],\n        \n        # [BOS]8.1or2.95[SEP]\n        [15, 8, 10, 1, 11, 2, 10, 9, 5, 17],\n        \n        # [BOS]125or115[SEP]\n        [15, 1, 2, 5, 11, 1, 1, 5, 17],\n        \n        # [BOS]21.01or21.02[SEP]\n        [15, 2, 1, 10, 0, 1, 11, 2, 1, 10, 0, 2, 17]\n    ]\n    \n    # Test the model on examples\n    print(\"\\nTesting the improved fine-tuned model:\")\n    for i, input_sequence in enumerate(test_examples):\n        generated_sequence = model.generate(input_sequence)\n        \n        # Print results\n        id_to_token = finetuner.id_to_token\n        input_text = \"\".join([id_to_token[token_id] for token_id in input_sequence])\n        generated_text = \"\".join([id_to_token[token_id] for token_id in generated_sequence])\n        \n        # Parse numbers for expected result\n        num1, num2 = finetuner.parse_numbers(input_sequence)\n        if num1 is not None and num2 is not None:\n            op = '<' if num1 < num2 else '>' if num1 > num2 else '='\n            expected = f\"{num1}{op}{num2}\"\n        else:\n            expected = \"Unable to parse\"\n        \n        print(f\"Example {i+1}:\")\n        print(f\"Input: {input_text}\")\n        print(f\"Generated: {generated_text}\")\n        print(f\"Expected: {expected}\")\n        print(\"-\" * 50)\n    \n    return model\n\n# Run the improved fine-tuning\nimproved_model = run_improved_finetuning()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:59:27.214255Z","iopub.execute_input":"2025-03-20T18:59:27.214561Z"}},"outputs":[{"name":"stderr","text":"INFO: Seed set to 42\n","output_type":"stream"},{"name":"stdout","text":"Generating training data...\nGenerating validation data...\nInitial evaluation:\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 8/8 [00:28<00:00,  3.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Evaluation Results: 301/500 correct = 0.6020 accuracy\n\nEpoch 1/3:\n","output_type":"stream"},{"name":"stderr","text":"Training:  57%|█████▋    | 45/79 [03:34<02:41,  4.74s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### RL","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndef train_one_epoch(self, dataloader):\n    \"\"\"\n    Train the model for one epoch using policy gradient (REINFORCE).\n    \n    Args:\n        dataloader: DataLoader providing batches of input sequences.\n    \n    Returns:\n        avg_reward (float): Average reward over the epoch.\n        accuracy (float): Fraction of correct predictions.\n    \"\"\"\n    self.model.train()\n    total_reward = 0.0\n    total_correct = 0\n    total_samples = 0\n    \n    for batch in tqdm(dataloader, desc=\"Training\"):\n        batch = batch.to(self.model.device)\n        batch_size = batch.size(0)\n        loss = 0.0\n        \n        for i in range(batch_size):\n            # Extract input sequence up to [SEP]\n            sep_positions = (batch[i] == 17).nonzero(as_tuple=True)[0]\n            if len(sep_positions) == 0:\n                continue  # Skip if [SEP] is not found\n            sep_position = sep_positions[0].item()\n            input_seq = batch[i, :sep_position + 1].clone()  # e.g., [BOS] num1 or num2 [SEP]\n            current_seq = input_seq.clone()\n            \n            log_probs = []  # Store log probabilities of sampled tokens\n            generated = []  # Store generated tokens\n            max_generation_len = 10  # Maximum tokens to generate after [SEP]\n            \n            # Generate sequence autoregressively by sampling\n            while len(generated) < max_generation_len and (len(generated) == 0 or generated[-1] != 16):\n                # Create causal mask\n                mask = self.model.generate_square_subsequent_mask(current_seq.size(0)).to(self.model.device)\n                \n                # Forward pass to get logits for the next token\n                output = self.model(current_seq.unsqueeze(0), mask)\n                logits = output[0, -1, :]  # Logits for the last position\n                \n                # Convert logits to log probabilities\n                log_probs_t = F.log_softmax(logits, dim=-1)\n                probs = log_probs_t.exp()\n                \n                # Sample a token from the policy\n                token = torch.multinomial(probs, num_samples=1).item()\n                \n                # Record the log probability of the sampled token\n                selected_log_prob = log_probs_t[token]\n                log_probs.append(selected_log_prob)\n                \n                # Append token to generated sequence\n                generated.append(token)\n                \n                # Update current sequence for the next iteration\n                current_seq = torch.cat([current_seq, torch.tensor([token], device=self.model.device)], dim=0)\n            \n            # Construct the full generated sequence\n            full_generated_seq = input_seq.tolist() + generated\n            \n            # Compute reward using the existing method\n            R = self.compute_reward(full_generated_seq, full_generated_seq)\n            total_reward += R\n            if R > 0:\n                total_correct += 1\n            total_samples += 1\n            \n            # Compute policy gradient loss for this sequence\n            if log_probs:\n                total_log_prob = sum(log_probs)  # Sum log probs over the sequence\n                loss_i = -total_log_prob * R     # Negative because we maximize reward\n                loss += loss_i\n        \n        # Average loss over the batch and update model\n        if total_samples > 0:\n            loss = loss / total_samples\n            self.optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)  # Gradient clipping\n            self.optimizer.step()\n    \n    # Compute epoch statistics\n    avg_reward = total_reward / max(total_samples, 1)\n    accuracy = total_correct / max(total_samples, 1)\n    \n    self.rewards_history.append(avg_reward)\n    self.accuracy_history.append(accuracy)\n    \n    print(f\"Epoch stats - Avg Reward: {avg_reward:.4f}, Accuracy: {accuracy:.4f}\")\n    return avg_reward, accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}